#unet
model:
    base_learning_rate: 1.0e-06
    target: ldm.models.ddpm.LatentDiffusion
    params:
      monitor: 'val/loss'
      timesteps: 1000
      embed_size: 4
      image_size: 16
      p_uncond: 0.2
      use_cfg: True
      cfg_scale: 5
      ckpt_path: checkpoints/ddpm/ldm_vgg.ckpt
      cond_key: sat_emb_vgg
      backbone_config: 
        target: ldm.models.unet.UNET
      first_stage_config:
        target: ldm.models.autoencoder.VAE
        params:
          emb_dim: 4
          lossconfig:
            target: torch.nn.Identity
          ddconfig:
            z_channels: 4
            resolution: 64
            in_ch: 3
            out_ch: 3
            ch: 32
            ch_mult: [1,2,4]      
            num_res_blocks: 2
            attn_resolutions: [16]
          ckpt_path: checkpoints/vae/16x16x4_vae.ckpt
      cond_stage_config:
        target: ldm.models.ddpm.SatelliteHead
        params:
          in_channels: 512
          out_channels: 128